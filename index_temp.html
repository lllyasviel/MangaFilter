<!DOCTYPE html>
<html lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Erasing Appearance Preservation in Optimization-based Smoothing</title>
	<link rel="stylesheet" type="text/css" href="./index_files/pixl-bk.css">
	<link rel="stylesheet" type="text/css" href="./index_files/pixl-fonts.css">
</head>

<body>

<div class="crumb">
	<a href="https://github.com/lllyasviel">Style2Paints Research</a> â†’
	[Zhang et al. 2021]
	</span>
</div>


<div class="content">
<div class="paperheader">
  <div class="papertitle"> Generating Manga from Illustrations via Mimicking Manga Creation Workflow </div>
  <br>
  <div class="pubinfo"> 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) </div>
  <br>
  <div class="authors"> <a href="https://github.com/lllyasviel">Lvmin Zhang</a>, Xinrui Wang, <a href="https://fqnchina.github.io/">Qingnan Fan</a>, Yi Ji, and Chunping Liu </div>
</div>

<div class="paperimg"><img src="./imgs/teaser.jpg"></div>
<div class="longcaption">Generating manga from illustrations. Our framework automatically generate the high-quality manga given the illustrations. The colorful images are inputs and the manga images are outputs.</div>
<div class="header">Abstract</div>
<p>
</p><div class="abstract">
  We present a framework to generate manga from digital illustrations. In professional mange studios, the manga creation workflow consists of three key steps: (1) Artists use line drawings to delineate the structural outlines in manga storyboards. (2) Artists apply several types of regular screentones to render the shading, occlusion, and object materials. (3) Artists selectively paste irregular screen textures onto the canvas to achieve various background layouts or special effects. Motivated by this workflow, we propose a data-driven framework to convert a digital illustration into three corresponding components: manga line drawing, regular screentone, and irregular screen texture. These components can be directly composed into manga images and can be further retouched for more plentiful manga creations. To this end, we create a large-scale dataset with these three components annotated by artists in a human-in-the-loop manner. We conduct both perceptual user study and qualitative evaluation of the generated manga, and observe that our generated image layers for these three components are practically usable in the daily works of manga artists. We provide 60 qualitative results and 15 additional comparisons in the supplementary material. We will make our presented manga dataset publicly available to assist related applications.
</div>
<div class="header">Files</div>
<ul>
<li> <a href=" ">Paper</a> (27.81MB, a PDF file) </li>
</ul>
<div class="header">See Also</div>
<ul>

<li> <a href=" ">Supplementary Document</a> - A document of additional results and engineering details.</li>

</ul>
<div class="header">Citation</div>
<p>
Lvmin Zhang, Xinrui Wang, Qingnan Fan, Yi Ji, and Chunping Liu.<br>
"Generating Manga from Illustrations via Mimicking Manga Creation Workflow."<br>
<i>2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i>, June 2021.
</p><div class="header">BibTeX</div>
<p>
</p><pre>@InProceedings{EAP2020,
    author={Lvmin Zhang and Xinrui Wang and Qingnan Fan and Yi Ji and Chunping Liu}, 
    booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
    title={Generating Manga from Illustrations via Mimicking Manga Creation Workflow}, 
    year={2021}, 
    }
</pre>
</div>


</body></html>
